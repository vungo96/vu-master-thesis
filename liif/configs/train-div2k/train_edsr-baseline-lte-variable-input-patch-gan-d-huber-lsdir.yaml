train_dataset:
  dataset:
    name: image-folder
    args:
      root_path: ./load/LSDIR/train/HR
      repeat: 1
      # cache: in_memory
      sharded: true
  wrapper:
    name: sr-implicit-downsampled-collate-batch
    args:
      inp_sizes: [64]
      augment: true
      sample_q: 4096
      sample_patch: true
      # limit_scale: 4 # change scale_min
      scale_min: 1
      # scale_max: 4
      plot_scales: true
  collate_batch: true
  batch_size: 32

gan_based: true

gradient_accumulation_steps: 1

val_dataset:
  dataset:
    name: image-folder
    args:
      root_path: ./load/div2k/DIV2K_valid_HR
      first_k: 10
      repeat: 160
      cache: in_memory
  wrapper:
    name: sr-implicit-downsampled-collate-batch
    args:
      inp_sizes: [64]
      augment: true
      sample_q: 4096
      sample_patch: true
      # limit_scale: 3
      scale_min: 1
      # scale_max: 4
  collate_batch: true
  batch_size: 32

data_norm:
  inp: {sub: [0.5], div: [0.5]}
  gt: {sub: [0.5], div: [0.5]}
  # inp_scale_max: 64

model:
  name: lte
  args:
    encoder_spec:
      name: edsr-baseline
      args:
        no_upsampling: true
    imnet_spec:
      name: mlp
      args:
        out_dim: 3
        hidden_list: [256, 256, 256]
    hidden_dim: 256
    # scale_aware_phase: true
    # scale_aware_mlp: true

optimizer:
  name: adam
  args:
    lr: 1.e-5
multi_step_lr:
  milestones: [400000, 800000, 1200000, 1600000]
  gamma: 0.5

optimizer_D:
  name: adam
  args:
    lr: 1.e-5
multi_step_lr_D:
  milestones: [400000, 800000, 1200000, 1600000]
  gamma: 0.5

loss_fn: huber

pre-trained: save_test/_train_edsr-baseline-lte-variable-input-lsdir2_sample-4096-scale-1toMax-batch-32-inputs-48-lsdir/epoch-400.pth

iter_max: 2000000
iter_val: 100000
iter_save: 100000
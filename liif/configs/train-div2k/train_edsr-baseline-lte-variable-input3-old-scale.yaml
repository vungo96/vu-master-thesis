train_dataset:
  dataset:
    name: image-folder
    args:
      root_path: ./load/div2k/DIV2K_train_HR
      repeat: 20
      cache: in_memory
  wrapper:
    name: sr-implicit-downsampled-collate-batch
    args:
      inp_sizes: [42, 48, 56]
      augment: true
      sample_q: 4096
      # limit_scale: 4 # change scale_min
      scale_min: 1
      plot_scales: true
  collate_batch: true
  batch_size: 16

gradient_accumulation_steps: 1

val_dataset:
  dataset:
    name: image-folder
    args:
      root_path: ./load/div2k/DIV2K_valid_HR
      first_k: 10
      repeat: 160
      cache: in_memory
  wrapper:
    name: sr-implicit-downsampled-collate-batch
    args:
      inp_sizes: [48]
      augment: true
      sample_q: 2304
      # limit_scale: 3
      scale_min: 12
      # scale_max: 12
  collate_batch: true
  batch_size: 32

val_dataset2:
  dataset:
    name: image-folder
    args:
      root_path: ./load/Set5/HR
      repeat: 80
      cache: in_memory
  wrapper:
    name: sr-implicit-downsampled-collate-batch
    args:
      inp_sizes: [48]
      augment: true
      sample_q: 2304
      # limit_scale: 1
      scale_min: 4
      scale_max: 4
  collate_batch: true
  batch_size: 32

data_norm:
  inp: {sub: [0.5], div: [0.5]}
  gt: {sub: [0.5], div: [0.5]}
  inp_scale_max: 64

model:
  name: lte-scale
  args:
    encoder_spec:
      name: edsr-baseline
      args:
        no_upsampling: true
    imnet_spec:
      name: mlp
      args:
        out_dim: 3
        hidden_list: [256, 256, 256]
    hidden_dim: 256
    # scale_aware_phase: true
    scale_aware_mlp: true

optimizer:
  name: adam
  args:
    lr: 1.e-4
epoch_max: 2000
multi_step_lr:
  milestones: [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800]
  gamma: 0.5

epoch_val: 1
epoch_save: 100
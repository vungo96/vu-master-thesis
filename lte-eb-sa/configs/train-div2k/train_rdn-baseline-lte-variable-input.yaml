train_dataset:
  dataset:
    name: image-folder
    args:
      root_path: ./load/div2k/DIV2K_train_HR
      repeat: 20
      cache: in_memory
  wrapper:
    name: sr-implicit-downsampled-collate-batch
    args:
      inp_sizes: [48]
      augment: true
      sample_q: 2304
      # limit_scale: 4 # change scale_min
      scale_min: 1
      scale_max: 4
      plot_scales: true
  collate_batch: true
  batch_size: 16

gradient_accumulation_steps: 1

val_dataset:
  dataset:
    name: image-folder
    args:
      root_path: ./load/div2k/DIV2K_valid_HR
      first_k: 10
      repeat: 160
      cache: in_memory
  wrapper:
    name: sr-implicit-downsampled
    args:
      inp_size: 48
      scale_max: 4
      sample_q: 2304
  collate_batch: false
  batch_size: 16

data_norm:
  inp: {sub: [0.5], div: [0.5]}
  gt: {sub: [0.5], div: [0.5]}

model:
  name: lte
  args:
    encoder_spec:
      name: rdn
      args:
        no_upsampling: true
    imnet_spec:
      name: mlp
      args:
        out_dim: 3
        hidden_list: [256, 256, 256]
    hidden_dim: 256

optimizer:
  name: adam
  args:
    lr: 1.e-4
iter_max: 1000000
multi_step_lr:
  milestones: [200000, 400000, 600000, 800000]
  gamma: 0.5

resume: save/_train_rdn-baseline-lte-variable-input_sample-2304-scale-1to4-inputs-48-baseline/iteration-600000.pth

iter_val: 100000
iter_save: 100000